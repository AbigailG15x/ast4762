{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc77ee-e425-46a3-a1f5-5fd633eabb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abigail Glover\n",
    "# ast 4762 - HW 8\n",
    "# 2023 November 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c7e00b-d8a4-4b7d-b329-6a14e172a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 2\n",
      "Data directory: hw6_data/\n",
      "FITS extensions: .fits\n",
      "Last object file: stars_13s_9\n",
      "Last dark file: dark_13s_5\n",
      "Date of Observation (DATE-OBS) from objects: 2002-01-27\n",
      "Date of Observation (DATE-OBS) from darks: 2002-01-27\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the filename for the median dark frame (for hw6 use dark_13s_med.fits):  dark_13s_med.fits\n"
     ]
    }
   ],
   "source": [
    "# Abigail Glover\n",
    "# October 9, 2023\n",
    "# HW 6\n",
    "\n",
    "## UPDATED 26 and 31 OCT 2023 by Abigail Glover\n",
    "# New error emerged that causes code to no longer run\n",
    "# Note that this error was not present in the original file\n",
    "# Could not find solution\n",
    "# More details included in log\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import rdpharo_win\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import sympy\n",
    "import math\n",
    "\n",
    "# Print problem statement\n",
    "print('Problem 2')\n",
    "\n",
    "# Define variables\n",
    "R = 3  # Read noise in photoelectrons\n",
    "N_star = 900  # Number of photoelectrons per second\n",
    "t1 = 5  # Exposure time in seconds\n",
    "S = 13  # Number of pixels\n",
    "p = 1  # Number of pixels\n",
    "\n",
    "# Number of exposures\n",
    "N_exposures1 = 10 \n",
    "\n",
    "# Calculate SNR for one exposure\n",
    "SNR_one_exposure = (N_star * t1) / math.sqrt(N_star * t1 + S * p * t1 + p * R**2)\n",
    "\n",
    "# Calculate total SNR for all exposures\n",
    "SNR_total = math.sqrt(N_exposures1) * SNR_one_exposure\n",
    "\n",
    "# Print the expression for the SNR\n",
    "#print('\\nThe expression to find the SNR for the sum of all signals (with the same conditions) over multiple exposures is:')\n",
    "#print('SNR = N_exposures * (N_star * t)/sqrt(N_star * t + S * p * t + p * R^2)')\n",
    "#print('\\nThe expression to find the SNR for the sum of all signals (with varying conditions) over multiple exposures is:')\n",
    "#print('SNR = sigma[ (N_star * t)/sqrt(N_star * t + S * p * t + p * R^2) ]')\n",
    "\n",
    "# Question\n",
    "#print('\\n\\nWhat is the SNR if you take ten 5-second exposures?')\n",
    "\n",
    "# Answer\n",
    "#print(f\"The SNR for ten 5-second exposures is: {SNR_total : .2f}\")\n",
    "\n",
    "# Update variables\n",
    "t2 = 50 # Exposure time in seconds\n",
    "N_exposures2 = 1\n",
    "\n",
    "# Calculate SNR for updated exposure\n",
    "SNR_one_exposure2 = (N_star * t2) / math.sqrt(N_star * t2 + S * p * t2 + p * R**2)\n",
    "\n",
    "# Calculate total SNR for all updated exposures\n",
    "SNR_total2 = math.sqrt(N_exposures2) * SNR_one_exposure2\n",
    "\n",
    "# Question\n",
    "#print('\\n\\nHow about when taking just one 50-second integration?')\n",
    "\n",
    "#Answer\n",
    "#print(f\"The SNR for one 50-second exposure is: {SNR_total2 : .2f}\")\n",
    "\n",
    "# Question\n",
    "#print('\\n\\nWhich is better and why?')\n",
    "\n",
    "# Update variables\n",
    "t2 = 50 # Exposure time in seconds\n",
    "N_exposures2 = 1\n",
    "\n",
    "# Calculate SNR for updated exposure\n",
    "SNR_one_exposure2 = (N_star * t2) / math.sqrt(N_star * t2 + S * p * t2 + p * R**2)\n",
    "\n",
    "# Calculate total SNR for all updated exposures\n",
    "SNR_total2 = math.sqrt(N_exposures2) * SNR_one_exposure2\n",
    "\n",
    "# Question\n",
    "# #print('\\n\\nHow about when taking just one 50-second integration?')\n",
    "\n",
    "# Answer\n",
    "# #print(f\"The SNR for one 50-second exposure is: {SNR_total2 : .2f}\")\n",
    "\n",
    "# Question\n",
    "# print('\\n\\nWhich is better and why?')\n",
    "\n",
    "# Answer\n",
    "#print('A single, longer exposure is better than multiple short exposures.')\n",
    "#print('This is because a longer exposure allows more time for light from\\n\\\n",
    "#faint, deep-sky objects to be gathered, typically resulting in clearer,\\n\\\n",
    "#more detailed images in darker areas than short exposures provide.')\n",
    "\n",
    "# Question\n",
    "# print('\\n\\nWhat are some other practical considerations (pro or con) besides just the hypothetical SNR?')\n",
    "\n",
    "# Answer for short exposures\n",
    "#print('Considerations for short exposures:')\n",
    "#print('- PRO: Taking multiple short exposures reduces the risk of losing the entire (or most of the) data set.')\n",
    "#print('- PRO: It is easier to gather calibration frames from short exposures')\n",
    "#print('- PRO: There is less risk of oversaturating the pixels with short exposures')\n",
    "#print('- CON: Greater demand for data management.')\n",
    "#print('- CON: May not be an effective use of telescope time')\n",
    "#print('- CON: There is more noise in the data')\n",
    "\n",
    "# Answer for long exposures\n",
    "# print('\\nConsiderations for long exposures:')\n",
    "#print('- PRO: Noise is minimized')\n",
    "#print('- PRO: Can be a more efficient use of telescope time')\n",
    "#print('- PRO: Better signal-to-noise ratio')\n",
    "#print('- PRO: Provides more information (more data) from darker objects')\n",
    "#print('- CON: May cause oversaturation in pixels depending on the observed object')\n",
    "#print('- CON: Increased risk of higher data loss if something is corrupt')\n",
    "#print('- CON: More difficulty in gathering calibration frames')\n",
    "\n",
    "# print('\\nNote: There is no one answer for which exposure is better. Often,\\n\\\n",
    "# of the two is used by professionals depending on their research needs.')\n",
    "\n",
    "# Question\n",
    "# print('\\n\\nNote that the CCD Equation in Howell is for calculating one frameâ€™s SNR.')\n",
    "# print('How would you modify it for multiple exposures?')\n",
    "\n",
    "# Answer\n",
    "# print('To account for more than one exposure with the same conditions, I multiplied the number\\n\\\n",
    "# of exposures by the SNR equation for a single frame to get the total SNR value.')\n",
    "\n",
    "# Print problem statement\n",
    "# print('Problem 3')\n",
    "# print('Part a.)')\n",
    "\n",
    "\n",
    "## FIXED 2 Nov 2023\n",
    "## Made datadir2 to save dark med file to current directory\n",
    "\n",
    "# Data directory name\n",
    "datadir = \"hw6_data/\"\n",
    "\n",
    "# FITS extension string (including the dot, e.g., \".fits\")\n",
    "fext = \".fits\"\n",
    "\n",
    "# Print statement to let user know what has been done\n",
    "# print('\\nData directory name assigned.')\n",
    "# print('FITS extension assigned to variable')\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nPart b.)\\n')\n",
    "\n",
    "# Initialize empty lists for objects and darks\n",
    "objfile = []\n",
    "darkfile = []\n",
    "\n",
    "# List all files in the data directory\n",
    "file_list = os.listdir(datadir)\n",
    "\n",
    "# Iterate through the file names and categorize them\n",
    "for file_name in file_list:\n",
    "    \n",
    "    ## FIXED 2 Nov 2023\n",
    "    ## Added a conditional statement so that it does not read in the final file from\n",
    "    ## this homework assignment\n",
    "    \n",
    "    # Check if the file starts with \"stars_13s_\"\n",
    "    if file_name.startswith(\"stars_13s_\") and not \"nosky\" in file_name:\n",
    "        \n",
    "        # Remove the \".fits\" extension and add to the objects list\n",
    "        objfile.append(file_name.replace(fext, \"\"))\n",
    "\n",
    "\n",
    "    ## FIXED 2 Nov 2023\n",
    "    ## Added a conditional statement so that it does not read in the \n",
    "    ## med file from this assignment\n",
    "    \n",
    "    # Check if the file starts with \"dark_13s_\"\n",
    "    elif file_name.startswith(\"dark_13s_\") and not \"med\" in file_name:\n",
    "        \n",
    "        # Remove the \".fits\" extension and add to the darks list\n",
    "        darkfile.append(file_name.replace(fext, \"\"))\n",
    "\n",
    "# Print the lists (as a check to make sure they were correctly sorted)\n",
    "# #print(\"Object Files:\")\n",
    "# #print(objfile)\n",
    "# #print(\"\\nDark Files:\")\n",
    "# #print(darkfile)\n",
    "\n",
    "# Print statement to let user know what has been done\n",
    "# print('Files have been sorted.')\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nPart c.)\\n')\n",
    "\n",
    "# Print informative statements\n",
    "print(\"Data directory: \" + datadir)\n",
    "print(\"FITS extensions: \" + fext)\n",
    "\n",
    "# Print the last elements of objfile and darkfile\n",
    "if objfile:\n",
    "    print(\"Last object file: \" + objfile[-1])\n",
    "else:\n",
    "    print(\"No object files found.\")\n",
    "if darkfile:\n",
    "    print(\"Last dark file: \" + darkfile[-1])\n",
    "else:\n",
    "    print(\"No dark files found.\")\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nPart d.)\\n')\n",
    "\n",
    "# Choose a random file\n",
    "random_object_file = random.choice(objfile)\n",
    "\n",
    "# Construct the full path to the random file\n",
    "random_object_file_path = os.path.join(datadir, random_object_file + \".fits\")\n",
    "\n",
    "# Use rdpharo_win to read the data and header\n",
    "header, data = rdpharo_win.rdpharo(random_object_file_path)\n",
    "\n",
    "# Unpack the data from the array\n",
    "ny, nx = data.shape[0], data.shape[1]\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nPart e.)\\n')\n",
    "\n",
    "# Define variables\n",
    "nobj = len(objfile)\n",
    "ndark = len(darkfile)\n",
    "\n",
    "# print ny, nx, nobj, and ndark\n",
    "#print(f\"Data array size (ny): {ny}\")\n",
    "#print(f\"Data array size (nx): {nx}\")\n",
    "#print(f\"Number of files in objfile: {nobj}\")\n",
    "#print(f\"Number of files in darkfile: {ndark}\")\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nProblem 4')\n",
    "# print('Part a.)\\n')\n",
    "\n",
    "# Allocate 3D float arrays \n",
    "objects_array = np.zeros((nobj, ny, nx), dtype=float)\n",
    "darks_array = np.zeros((ndark, ny, nx), dtype=float)\n",
    "\n",
    "# Print the shapes of the arrays\n",
    "# #print(\"Shape of objects array:\", objects_array.shape)\n",
    "# #print(\"Shape of darks array:\", darks_array.shape)\n",
    "\n",
    "# Print problem statement\n",
    "# #print('\\nPart b.)\\n')\n",
    "\n",
    "# Initialize header variables\n",
    "objhead = None\n",
    "darkhead = None\n",
    "\n",
    "# Read data into the arrays\n",
    "# For objects\n",
    "for i, obj_filename in enumerate(objfile):\n",
    "    obj_path = os.path.join(datadir, obj_filename + \".fits\")\n",
    "    obj_output = rdpharo_win.rdpharo(obj_path)\n",
    "\n",
    "    if len(obj_output) == 2:\n",
    "        obj_header, obj_data = obj_output\n",
    "        objects_array[i] = obj_data\n",
    "        objhead = obj_header\n",
    "    else:\n",
    "        print(f\"Error reading object file: {obj_filename}\")\n",
    "\n",
    "# For darks\n",
    "for j, dark_filename in enumerate(darkfile):\n",
    "    dark_path = os.path.join(datadir, dark_filename + \".fits\")\n",
    "    dark_output = rdpharo_win.rdpharo(dark_path)\n",
    "\n",
    "    if len(dark_output) == 2:\n",
    "        dark_header, dark_data = dark_output\n",
    "        darks_array[j] = dark_data\n",
    "        darkhead = dark_header\n",
    "    else:\n",
    "        print(f\"Error reading dark file: {dark_filename}\")\n",
    "\n",
    "# Print the DATE-OBS from the last headers\n",
    "if objhead is not None:\n",
    "    print(\"Date of Observation (DATE-OBS) from objects:\", objhead.get(\"DATE-OBS\", \"Not available\"))\n",
    "if darkhead is not None:\n",
    "    print(\"Date of Observation (DATE-OBS) from darks:\", darkhead.get(\"DATE-OBS\", \"Not available\"))\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nExtra Credit\\n')\n",
    "\n",
    "# Print question\n",
    "# print('Why not print TIME-OBS?')\n",
    "\n",
    "# Sample code to test\n",
    "# Find the time OBS for objects and print result\n",
    "# #if objhead is not None:\n",
    "# #    time_obs_obj = objhead.get('TIME-OBS', 'N/A')\n",
    "# #    print(f\"TIME-OBS from objects: {time_obs_obj}\")\n",
    "# #else:\n",
    "# #    print(\"No object header found.\")\n",
    "\n",
    "# Find the time OBS for darks and print result\n",
    "# #if darkhead is not None:\n",
    "# #    time_obs_dark = darkhead.get('TIME-OBS', 'N/A')\n",
    "# #    print(f\"TIME-OBS from darks: {time_obs_dark}\")\n",
    "# #else:\n",
    "# #    print(\"No dark header found.\")\n",
    "\n",
    "# Answer\n",
    "# print('\\nFor these specific files, the objects did not provide the time\\n\\\n",
    "# of the observation, meaning that it may not have been recorded or\\n\\\n",
    "# was possibly corrupted. Typically, researchers would prefer both\\n\\\n",
    "# the date and time of observations to maximize the data. However,\\n\\\n",
    "# while time provides specific information about when an observation\\n\\\n",
    "# occurred within a specific day, the date offers a broader context\\n\\\n",
    "# and is relevant for various applications. So if having to choose\\n\\\n",
    "# of the two, it is more beneficial to print the date.')\n",
    "\n",
    "# Print problem statement\n",
    "# print('\\nProblem 5')\n",
    "# print('Part a - d.)\\n')\n",
    "\n",
    "# Call the numpy median function on the dark data\n",
    "median_dark = np.median(darks_array, axis=0)\n",
    "\n",
    "# Print the value of the pixel index\n",
    "pixel_value = median_dark[217, 184]\n",
    "# print(f\"Value of pixel index [217, 184]: {pixel_value}\")\n",
    "\n",
    "# Add history to the dark header\n",
    "if darkhead is not None:\n",
    "    darkhead.add_history(\"Median combination dark frame\")\n",
    "    \n",
    "    # Specify headers causing issues\n",
    "    problem_cards = ['CDELT1', 'CDELT2', 'RA_OFFS', 'DEC_OFFS', 'RA_RATE', 'DEC_RATE']\n",
    "\n",
    "    # Find problem cards in the header and remove them\n",
    "    for card_name in problem_cards:\n",
    "        if card_name in darkhead:\n",
    "            del darkhead[card_name]\n",
    "\n",
    "# Write the median dark (with modified header) to a new fits file\n",
    "output_dark_filename = input(\"Enter the filename for the median dark frame (for hw6 use dark_13s_med.fits): \")\n",
    "\n",
    "## FIXED 2 Nov 2023 \n",
    "## Removed directory to hw6 data\n",
    "\n",
    "# Save the file in the current working folder\n",
    "#output_dark_path = os.path.join(datadir2, output_dark_filename)\n",
    "\n",
    "# Create a new header data unit with the median dark data and the modified header\n",
    "median_dark_hdu = fits.PrimaryHDU(data=median_dark, header=darkhead)\n",
    "\n",
    "## FIXED 2 Nov 2023 Changed path to file name\n",
    "# Save the HDU to a new FITS file\n",
    "median_dark_hdu.writeto(output_dark_filename, overwrite=True)\n",
    "\n",
    "# Let the user know where the new file has been saved\n",
    "# print(f\"\\nMedian dark frame successfully saved as {output_dark_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2acc2ff-edc2-4ae6-a8ce-675838237188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4\n",
      "Normalization Factors:\n",
      "11002.0\n",
      "11195.0\n",
      "10673.0\n",
      "10696.0\n",
      "11184.0\n",
      "10761.0\n",
      "10053.0\n",
      "10054.0\n",
      "9998.0\n",
      "\n",
      "Problem 5\n",
      "\n",
      "Value of pixel [217, 184] in the last frame: 9887.000994727941\n"
     ]
    }
   ],
   "source": [
    "########## HW 7 START ##########\n",
    "\n",
    "# Print problem statement\n",
    "print('Problem 4')\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import hw7_abigailglover_support_functions\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the normalization region\n",
    "norm_region = ((225, 225), (-225, -225))\n",
    "\n",
    "# Call the normmedcomb function with the data and normalization region\n",
    "median_combined, normalization_factors = hw7_abigailglover_support_functions.normmedcomb(objects_array, norm_region)\n",
    "\n",
    "# Visually verify that there are no stars left\n",
    "# plt.imshow(median_combined, cmap='gray', origin='lower')\n",
    "# plt.title('Normalized Sky Frame')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# Save median_combined to the FITS file\n",
    "fits.writeto('sky_13s_mednorm.fits', median_combined, overwrite=True)\n",
    "\n",
    "# Print normalization factors\n",
    "print(\"Normalization Factors:\")\n",
    "for factor in normalization_factors:\n",
    "    print(factor)\n",
    "\n",
    "# Print problem statement\n",
    "print('\\nProblem 5\\n')\n",
    "\n",
    "# Create a copy of the object data\n",
    "object_data_copy = objects_array.copy()\n",
    "\n",
    "# Define the normalization region\n",
    "norm_region = ((225, 225), (-225, -225))\n",
    "\n",
    "# Define the FITS file name\n",
    "output_fits_file = \"stars_13s_9_nosky.fits\" \n",
    "\n",
    "# Write the last resulting frame to a FITS file\n",
    "last_object_frame = object_data_copy[-1]\n",
    "output_path = os.path.join(datadir, output_fits_file)\n",
    "fits.writeto(output_path, last_object_frame, overwrite=True) \n",
    "\n",
    "# Iterate through each frame in the object data\n",
    "for i in range(object_data_copy.shape[0]):\n",
    "    # Call the skycormednorm function on each frame\n",
    "    object_data_copy[i] = hw7_abigailglover_support_functions.skycormednorm(object_data_copy[i], median_combined, norm_region)\n",
    "    \n",
    "# Print the value of pixel [217, 184]\n",
    "pixel_value = last_object_frame[217, 184]\n",
    "print(f\"Value of pixel [217, 184] in the last frame: {pixel_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20986b86-06c3-45d0-aa3b-b1fab3668215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 512, 512)\n",
      "(5, 4, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "##### HW 8 START #####\n",
    "\n",
    "# Import Libraries\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import medcombine\n",
    "\n",
    "# Define the folder and file names\n",
    "data_folder = \"hw6_data\"\n",
    "lamp_on_files = [f\"{data_folder}/k_lampon_{i}.fits\" for i in range(1, 6)]\n",
    "lamp_off_files = [f\"{data_folder}/k_lampoff_{i}.fits\" for i in range(1, 6)]\n",
    "\n",
    "# Load the data from the lamp-on and lamp-off files\n",
    "lamp_on_data = [fits.getdata(file) for file in lamp_on_files]\n",
    "lamp_off_data = [fits.getdata(file) for file in lamp_off_files]\n",
    "\n",
    "print(np.shape(lamp_on_data))\n",
    "print(np.shape(lamp_off_data))\n",
    "\n",
    "# Convert the lists of data into NumPy arrays with dtype 'float64'\n",
    "lamp_on_data = np.array(lamp_on_data, dtype=np.float64)\n",
    "lamp_off_data = np.array(lamp_off_data, dtype=np.float64)\n",
    "\n",
    "# Print the shape to check\n",
    "#print(np.shape(lamp_on_data))\n",
    "#print(np.shape(lamp_off_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd5c9980-7f6b-4bc9-ae05-407103375f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 512, 512)\n",
      "(4, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Combine the lamp-on and lamp-off sets separately using median combination\n",
    "lamp_on_median, _ = medcombine.normmedcomb(lamp_on_data)\n",
    "lamp_off_median, _ = medcombine.normmedcomb(lamp_off_data)\n",
    "\n",
    "# Print the shape of the median-combined data\n",
    "#print(np.shape(lamp_on_median))\n",
    "#print(np.shape(lamp_off_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eed04f81-ede2-474c-b945-b755cacd7cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Subtract the lamp-off median frame from the lamp-on\n",
    "# Access the specific elements of the tuples\n",
    "flat_field = np.abs(lamp_on_median[0] - lamp_off_median[0])\n",
    "\n",
    "# Print the shape to check\n",
    "#print(np.shape(flat_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebbca0ff-db30-47b6-b9bb-150befe2c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization region\n",
    "norm_region = ((225, 225), (-225, -225))\n",
    "\n",
    "# Create a mask for the normalization region\n",
    "mask = np.zeros_like(flat_field, dtype=bool)\n",
    "mask[norm_region[0][0]:norm_region[1][0], norm_region[0][1]:norm_region[1][1]] = True\n",
    "\n",
    "# Use the mask to extract the data within the normalization region\n",
    "norm_data = flat_field[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebe671a7-9282-405c-97c0-62cdf54c6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value within the normalization region\n",
    "norm_median = np.median(norm_data)\n",
    "\n",
    "# Normalize the flat field by dividing by the median value\n",
    "flat_field_normalized = flat_field / norm_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b307b49c-4ace-4910-9c34-c8829adb34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the flat field to flat.fits\n",
    "fits.writeto(\"flat.fits\", flat_field_normalized, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7efa0ef-a102-415b-9b70-b4eb6a1ce299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel value at [217, 184]: 1.1342786004988392\n"
     ]
    }
   ],
   "source": [
    "# Print the value of pixel index [217, 184] from the result\n",
    "print(\"Pixel value at [217, 184]:\", flat_field_normalized[217, 184])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4aa6c81-6191-4b57-ab3a-7046b8c8e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part b.\n",
      "Pixel values at [217, 184] in each frame:\n",
      "Frame 0: 55820.490276605786\n",
      "Frame 1: 57637.042193405156\n",
      "Frame 2: 54799.321261229874\n",
      "Frame 3: 55635.75618337196\n",
      "Frame 4: 57724.27773743225\n",
      "Frame 5: 54917.345820795934\n",
      "Frame 6: 51530.55411150898\n",
      "Frame 7: 50945.56281626851\n",
      "Frame 8: 50735.17121008553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abigail Glover\\AppData\\Local\\Temp\\ipykernel_30816\\1368749420.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  object_data_copy_normalized = object_data_copy / expanded_flat_field\n",
      "C:\\Users\\Abigail Glover\\AppData\\Local\\Temp\\ipykernel_30816\\1368749420.py:19: DeprecationWarning: Assigning the 'data' attribute is an inherently unsafe operation and will be removed in the future.\n",
      "  last_frame_with_header.data = object_data_copy_normalized[-1]  # Replace the data with the normalized frame\n"
     ]
    }
   ],
   "source": [
    "# Print problem statement\n",
    "print('Part b.')\n",
    "\n",
    "# Expand flat_field_normalized to match the shape of object_data_copy\n",
    "expanded_flat_field = np.repeat(flat_field_normalized, 2, axis=0)\n",
    "expanded_flat_field = np.repeat(expanded_flat_field, 2, axis=1)\n",
    "\n",
    "# Apply the flat field to the object data\n",
    "object_data_copy_normalized = object_data_copy / expanded_flat_field\n",
    "\n",
    "# Print the value of pixel [217, 184] in each frame\n",
    "pixel_values = object_data_copy_normalized[:, 217, 184]\n",
    "print(\"Pixel values at [217, 184] in each frame:\")\n",
    "for i, value in enumerate(pixel_values):\n",
    "    print(f\"Frame {i}: {value}\")\n",
    "\n",
    "# Write/print the last resulting frame with modified header\n",
    "last_frame_with_header = last_object_frame.copy()  # Copy the header of the last frame\n",
    "last_frame_with_header.data = object_data_copy_normalized[-1]  # Replace the data with the normalized frame\n",
    "fits.writeto(\"stars_13s_9_flat.fits\", last_frame_with_header, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "99b215a7-7a82-4a4d-9c35-d2ef67ecdc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4\n"
     ]
    }
   ],
   "source": [
    "# Print problem statement\n",
    "print('Problem 4')\n",
    "\n",
    "# Import libraries\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.io import fits\n",
    "\n",
    "# Define the data folder\n",
    "data_folder = \"hw6_data\"\n",
    "\n",
    "# Specify the fits files\n",
    "fits_files = [\"stars_13s_1.fits\", \"stars_13s_2.fits\", \"stars_13s_3.fits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adf91364-ee69-47e8-a2c9-fb6d5d4cc607",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "filter weights array has incorrect shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m daofind \u001b[38;5;241m=\u001b[39m DAOStarFinder(fwhm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45.0\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Find stars in the FITS image\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m sources \u001b[38;5;241m=\u001b[39m \u001b[43mdaofind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\photutils\\detection\\core.py:27\u001b[0m, in \u001b[0;36mStarFinderBase.__call__\u001b[1;34m(self, data, mask)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_stars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\photutils\\detection\\daofinder.py:266\u001b[0m, in \u001b[0;36mDAOStarFinder.find_stars\u001b[1;34m(self, data, mask)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_stars\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    Find stars in an astronomical image.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        `None` is returned if no stars are found.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_raw_catalog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\photutils\\detection\\daofinder.py:204\u001b[0m, in \u001b[0;36mDAOStarFinder._get_raw_catalog\u001b[1;34m(self, data, mask)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_raw_catalog\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 204\u001b[0m     convolved_data \u001b[38;5;241m=\u001b[39m \u001b[43m_filter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcheck_normalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxycoords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m         xypos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_stars(convolved_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[0;32m    210\u001b[0m                                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_eff, mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    211\u001b[0m                                  exclude_border\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_border)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\photutils\\utils\\_convolution.py:78\u001b[0m, in \u001b[0;36m_filter_data\u001b[1;34m(data, kernel, mode, fill_value, check_normalization)\u001b[0m\n\u001b[0;32m     74\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# NOTE: astropy.convolution.convolve fails with zero-sum kernels\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# (used in findstars) (cf. astropy #1647)\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# reapply the input unit\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:890\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(input, weights, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;129m@_ni_docstrings\u001b[39m\u001b[38;5;241m.\u001b[39mdocfiller\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvolve\u001b[39m(\u001b[38;5;28minput\u001b[39m, weights, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m'\u001b[39m, cval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m    785\u001b[0m              origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    786\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    Multidimensional convolution.\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    888\u001b[0m \n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_correlate_or_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:688\u001b[0m, in \u001b[0;36m_correlate_or_convolve\u001b[1;34m(input, weights, output, mode, cval, origin, convolution)\u001b[0m\n\u001b[0;32m    686\u001b[0m wshape \u001b[38;5;241m=\u001b[39m [ii \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m ii \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(wshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter weights array has incorrect shape.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convolution:\n\u001b[0;32m    690\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights[\u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m*\u001b[39m weights\u001b[38;5;241m.\u001b[39mndim)]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: filter weights array has incorrect shape."
     ]
    }
   ],
   "source": [
    "# Loop through the FITS files\n",
    "for i, fits_file in enumerate(fits_files):\n",
    "    # Construct the full path to the FITS file\n",
    "    fits_path = os.path.join(data_folder, fits_file)\n",
    "\n",
    "    # Read the FITS file\n",
    "    hdul = fits.open(fits_path)\n",
    "    data = hdul[0].data\n",
    "\n",
    "    # Initialize the object\n",
    "    daofind = DAOStarFinder(fwhm=5.0, threshold=5.0)\n",
    "\n",
    "    # Find stars in the FITS image\n",
    "    sources = daofind(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a9f21841-0f00-4710-8612-d5b76555cd6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the desired information for each star\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, source \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msources\u001b[49m):\n\u001b[0;32m      3\u001b[0m     y_guess, x_guess \u001b[38;5;241m=\u001b[39m source[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxcentroid\u001b[39m\u001b[38;5;124m'\u001b[39m], source[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mycentroid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStar \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: (a) y_guess: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_guess\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, (b) x_guess: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_guess\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sources' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the desired information for each star\n",
    "for j, source in enumerate(sources):\n",
    "    y_guess, x_guess = source['xcentroid'], source['ycentroid']\n",
    "    print(f\"Star {j}: (a) y_guess: {y_guess}, (b) x_guess: {x_guess}\")\n",
    "\n",
    "# Add your calculations to determine (c), (d), (e), (f), and (g) as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64b14b-d5cf-4b48-b8a5-c6e328a598ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from hw8 assignment\n",
    "# Stellar photometry:\n",
    "photometry = np.array( [ # yguess, xguess, width, cy, cx, star, sky\n",
    "# star 0\n",
    "[ [ 698, 512, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 0\n",
    "[fillin, fillin, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 1\n",
    "[fillin, fillin, np.nan, np.nan, np.nan, np.nan, np.nan] ], # frame 2\n",
    "# star 1\n",
    "[ [ 668, 520, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 0\n",
    "[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 1\n",
    "[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan] ] , # frame 2\n",
    "# star 2\n",
    "[ [ 568, 283, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 0\n",
    "[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan], # frame 1\n",
    "[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]] # frame 2\n",
    "], dtype=float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
